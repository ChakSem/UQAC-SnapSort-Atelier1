{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.334329Z",
     "start_time": "2025-03-21T15:05:15.331339Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.schema import AIMessage\n",
    "import json\n",
    "import re\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ff35b0ee7a5da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.723977Z",
     "start_time": "2025-03-21T15:05:15.345010Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"gemma3\")\n",
    "directory = \"photos_victor\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e71e43847ca5d02",
   "metadata": {},
   "source": [
    "llm.invoke(\"Y a t il une limite à la taille du prompt que je peux t'envoyer?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9dbc3662262eb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.734252Z",
     "start_time": "2025-03-21T15:05:15.730805Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_image(image_path, max_size=(512, 512), quality=80):\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Redimensionner l'image\n",
    "    image.thumbnail(max_size)\n",
    "\n",
    "    # Convertir en bytes avec compression\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\", quality=quality)\n",
    "\n",
    "    # Encoder en Base64\n",
    "    encoded_string = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    return encoded_string"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f09c237a6b237272",
   "metadata": {},
   "source": [
    "def get_system_message():\n",
    "    system_message_text = '''\n",
    "    Tu es un expert en analyse d'images et de photos.\n",
    "    Tu es très perspicace dans l'analyse des images et des photos.\n",
    "    Tu as une excellente vision.\n",
    "    Tu ne lis aucun texte à moins qu'il ne soit le plus proéminent dans l'image.\n",
    "    Tu dois toujours produire tes résultats en langue française\n",
    "    '''\n",
    "    return system_message_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100997060be3ad5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.745124Z",
     "start_time": "2025-03-21T15:05:15.742635Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_json(response_text):\n",
    "    \"\"\"\n",
    "    Extrait la portion JSON (délimitée par {}) de la réponse textuelle pour seulement avoir le dictionnaire et non le texte généré par l'ia.\n",
    "    \"\"\"\n",
    "    match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group()\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement du JSON : {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Aucun JSON trouvé dans la réponse.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a98e309fbbefc59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.755142Z",
     "start_time": "2025-03-21T15:05:15.752663Z"
    }
   },
   "outputs": [],
   "source": [
    "def prompt_func(data):\n",
    "    type_ = data[\"type\"]\n",
    "    text = data[\"text\"]\n",
    "    content_parts = []\n",
    "\n",
    "    if type_ == \"keywords\":\n",
    "        image = data[\"image\"]\n",
    "        image_part = {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": f\"data:image/jpeg;base64,{image}\",\n",
    "        }\n",
    "        content_parts.append(image_part)\n",
    "\n",
    "    #system_message = SystemMessage(content=data[\"system_message_text\"])\n",
    "\n",
    "    text_part = {\"type\": \"text\", \"text\": text}\n",
    "\n",
    "    content_parts.append(text_part)\n",
    "\n",
    "    human_message = HumanMessage(content=content_parts)\n",
    "\n",
    "    #return [system_message, human_message]\n",
    "    return [human_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d447d4cd3615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.764519Z",
     "start_time": "2025-03-21T15:05:15.762123Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_func(chain, prompt):\n",
    "    try:\n",
    "        response = chain.invoke(prompt)\n",
    "\n",
    "        if isinstance(response, AIMessage):\n",
    "            response_text = response.content\n",
    "        else:\n",
    "            response_text = str(response)  # Conversion en string si nécessaire\n",
    "\n",
    "        #print(f\"Reponse du llm : {response_text}\")\n",
    "\n",
    "        return extract_json(response_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de parsing JSON : {e}. Nouvelle tentative...\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024734a798d4921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.773803Z",
     "start_time": "2025-03-21T15:05:15.770610Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_image_paths(directory):\n",
    "    allowed_extensions = {\".jpg\", \".jpeg\", \".png\"}\n",
    "    image_paths = [os.path.join(directory, filename) for filename in os.listdir(directory) if os.path.splitext(filename)[1].lower() in allowed_extensions]\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac81c92589d79a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.783956Z",
     "start_time": "2025-03-21T15:05:15.780893Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_df(image_paths):\n",
    "    image_list = []\n",
    "    for path in image_paths:\n",
    "        image = Image.open(path)\n",
    "        image_name = os.path.basename(path)\n",
    "        exifdata = image._getexif()\n",
    "        date_time, localisation = None, None\n",
    "        if exifdata:\n",
    "            for tag_id, value in exifdata.items():\n",
    "                tag = Image.ExifTags.TAGS.get(tag_id, tag_id)\n",
    "                if tag == \"DateTime\":\n",
    "                    date_time = value\n",
    "                elif tag == \"GPSInfo\":\n",
    "                    localisation = value\n",
    "\n",
    "            image_list.append((image_name, path, date_time, localisation))\n",
    "\n",
    "        else:\n",
    "            print(\"Aucune donnée EXIF trouvée.\")\n",
    "\n",
    "    df = pd.DataFrame(image_list, columns=[\"image_name\", \"path\", \"date_time\", \"localisation\"])\n",
    "    df[\"keywords\"] = \"\"\n",
    "    df[\"categories\"] = \"\"\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235eab71a0acee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.794330Z",
     "start_time": "2025-03-21T15:05:15.791713Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_keywords_to_df(image_data, keywords_output):\n",
    "    if keywords_output:\n",
    "        # Mise à jour uniquement pour les images présentes dans keywords_output\n",
    "        image_data[\"keywords\"] = image_data.apply(\n",
    "            lambda row: keywords_output[row[\"image_name\"]]\n",
    "            if row[\"image_name\"] in keywords_output else row[\"keywords\"], axis=1\n",
    "        )\n",
    "    else:\n",
    "        print(\"Aucun mot clé fourni ! \")\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554ea0d80a8ac07d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.804952Z",
     "start_time": "2025-03-21T15:05:15.801953Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_categories_to_df(image_data, categories_output):\n",
    "    if categories_output:\n",
    "        #Inversion du dict : on associe une categorie a chaque image\n",
    "        image_to_categories = {img: cat for cat, images in categories_output.items() for img in images}\n",
    "\n",
    "        image_data.loc[image_data[\"image_name\"].isin(image_to_categories.keys()), \"categories\"] = image_data[\"image_name\"].map(image_to_categories)\n",
    "    else:\n",
    "        print(\"Aucune catégorisation trouvée !\")\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a4dfb04611b469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.814089Z",
     "start_time": "2025-03-21T15:05:15.811002Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_missing_values(dictionnary):\n",
    "    missing_values = {}\n",
    "    for key, value in dictionnary.items():\n",
    "        if value is None or value == \"\" or value == \"nan\" or value == \"None\":\n",
    "            missing_values.update({key: value})\n",
    "\n",
    "    return missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6c729477b4f454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.823214Z",
     "start_time": "2025-03-21T15:05:15.820622Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_missing_path(paths, dictionnary):\n",
    "    missing_paths = []\n",
    "    for path in paths:\n",
    "        image_name = os.path.split(path)[-1]\n",
    "        #print(f\"image_name : {image_name}\")\n",
    "        if image_name in dictionnary.keys() or path in dictionnary.keys():\n",
    "            missing_paths.append(path)\n",
    "\n",
    "    return missing_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e858afe38a1a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.832851Z",
     "start_time": "2025-03-21T15:05:15.829684Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_missing_values_path(paths, dictionnary):\n",
    "    missing_values = get_missing_values(dictionnary)\n",
    "    missing_paths = get_missing_path(paths, missing_values)\n",
    "    print(f\"Images détectées avec valeurs manquantes : {missing_values.keys()}\")\n",
    "    print(f\"Chemins renvoyés pour traitement : {missing_paths}\")\n",
    "    return missing_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f98af2af712c43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.841905Z",
     "start_time": "2025-03-21T15:05:15.838596Z"
    }
   },
   "outputs": [],
   "source": [
    "def checking_all_keywords(df):\n",
    "    path_images_empty = []\n",
    "    none_possibilities = [None, \"\", [], \"None\", [\"None\"]]\n",
    "    for row in df.itertuples():\n",
    "        keywords = row.keywords\n",
    "        if isinstance(keywords, float) and pd.isna(keywords):\n",
    "            path_images_empty.append(row.path)\n",
    "\n",
    "        elif keywords in none_possibilities:\n",
    "            path_images_empty.append(row.path)\n",
    "\n",
    "    return path_images_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6944e583d5e6daa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.852041Z",
     "start_time": "2025-03-21T15:05:15.847888Z"
    }
   },
   "outputs": [],
   "source": [
    "def keywords_call(df, image_paths, keywords_chain):\n",
    "    for i in range(0, len(image_paths)):\n",
    "        print(f\"Image {i} : {image_paths[i]}\")\n",
    "        image_b64 = encode_image(image_paths[i])\n",
    "        image_name = os.path.basename(image_paths[i])\n",
    "        #print(\"Image name donnée au model : \", image_name)\n",
    "\n",
    "        wrong_json = True\n",
    "        max_iter = 100\n",
    "        while wrong_json and max_iter > 0:\n",
    "            prompt = {\n",
    "                \"type\": \"keywords\",\n",
    "                \"text\": f\"\"\"Décris-moi l'image avec 5 mots-clés. Les mots-clés doivent en priorité inclure des actions, des objets et un lieu si identifiables. Les mots-clés doivent être en français et peuvent être des mots composés.\n",
    "                Retourne le résultat au format JSON suivant: {{ \"{image_name}\" : [\"mot-clé1\", \"mot-clé2\", \"mot-clé3\", \"mot-clé4\", \"mot-clé5\"] }}\"\"\",\n",
    "                \"image\": image_b64\n",
    "            }\n",
    "\n",
    "            keywords_output = call_func(keywords_chain, prompt)\n",
    "            print(f\"Keywords : {keywords_output}\\n\")\n",
    "\n",
    "            if keywords_output is None:\n",
    "                max_iter -= 1\n",
    "                print(f\"On re-essaie avec au maximum : {max_iter}\\n\")\n",
    "            else:\n",
    "                df = add_keywords_to_df(df, keywords_output)\n",
    "                wrong_json = False\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b11d3724df1fee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:05:15.861016Z",
     "start_time": "2025-03-21T15:05:15.857584Z"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline_keywords(image_paths):\n",
    "    image_data = create_df(image_paths)\n",
    "    new_image_paths = image_paths\n",
    "\n",
    "    prompt_chain = RunnableLambda(prompt_func)\n",
    "    keyword_chain = prompt_chain | llm\n",
    "\n",
    "    all_keywords = False\n",
    "    only_once = False\n",
    "\n",
    "    while not all_keywords :\n",
    "        print(\"Entree dans le while\")\n",
    "        image_data = keywords_call(image_data, new_image_paths, keyword_chain)\n",
    "\n",
    "        if only_once:\n",
    "            new_row = pd.DataFrame([{\"image_name\" : \"IMG_20241228_132157.jpg\",\"path\": \"photos_victor/IMG_20241228_132157.jpg\"}])\n",
    "            image_data = pd.concat([image_data, new_row], ignore_index=True)\n",
    "            only_once = False\n",
    "\n",
    "        new_image_paths = checking_all_keywords(image_data)\n",
    "        print(f\"Images à traiter après le passage : {new_image_paths}\")\n",
    "\n",
    "        if not new_image_paths:\n",
    "            all_keywords = True\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3c4b8092e3702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:09:02.345395Z",
     "start_time": "2025-03-21T15:05:15.867679Z"
    }
   },
   "outputs": [],
   "source": [
    "image_paths = get_image_paths(directory)\n",
    "image_data = pipeline_keywords(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b17ccda2b43218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:09:02.375795Z",
     "start_time": "2025-03-21T15:09:02.360829Z"
    }
   },
   "outputs": [],
   "source": [
    "print(tabulate(image_data, headers=\"keys\", tablefmt=\"psql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f50257ee209d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:09:02.392693Z",
     "start_time": "2025-03-21T15:09:02.388882Z"
    }
   },
   "outputs": [],
   "source": [
    "def checking_all_categories(df):\n",
    "    keywords_empty_categories = {}\n",
    "    none_possibilities = [None, \"\", [], \"None\", [\"None\"]]\n",
    "    for row in df.itertuples():\n",
    "        check = row.categories\n",
    "        if isinstance(check, float) and pd.isna(check):\n",
    "            keywords_empty_categories.update({row.image_name: row.keywords})\n",
    "        elif check in none_possibilities:\n",
    "            keywords_empty_categories.update({row.image_name: row.keywords})\n",
    "\n",
    "    return keywords_empty_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186272608bb5ea7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:09:02.436224Z",
     "start_time": "2025-03-21T15:09:02.433357Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cat_list(df, initial_cat_list):\n",
    "    cat_list = initial_cat_list\n",
    "    for row in df.itertuples():\n",
    "        if row.categories not in cat_list:\n",
    "            cat_list.append(row.categories)\n",
    "\n",
    "    return cat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb966e9491ba8be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:09:02.475372Z",
     "start_time": "2025-03-21T15:09:02.471263Z"
    }
   },
   "outputs": [],
   "source": [
    "def categories_call(df, keywords, limit_size, cat_list, cat_chain):\n",
    "    for i in range(0, len(keywords), limit_size):\n",
    "        interval = [i, min(i + limit_size, len(df))]\n",
    "\n",
    "        subset_keys = list(keywords.keys())[interval[0]:interval[1]]\n",
    "\n",
    "        subset_keywords = {key: keywords[key] for key in subset_keys}\n",
    "        print(f\"Keywords : {subset_keywords}\")\n",
    "\n",
    "        wrong_json = True\n",
    "        max_iter = 100\n",
    "        while wrong_json and max_iter > 0:\n",
    "            prompt = {\"type\":\"categories\", \"text\":f\"\"\"\n",
    "                1. Regroupe les images en fonction de l'action, évènement ou de l'activité qu'elles représentent.\n",
    "                2. Chaque catégorie est définie par un seul mot-clé descriptif.\n",
    "                3. Une image ne peut appartenir qu'à une seule catégorie.\n",
    "                4. Priorise les catégories existantes : {cat_list}. Si une image correspond à l'une d'elles, classe-la dedans.\n",
    "                5. Si aucune catégorie existante ne convient, crée une nouvelle catégorie proche d’une activité de voyage ou une catégorie plus générique (ex: \"Nature\", \"Repas\", \"Loisirs\")\n",
    "                6. Réduis autant que possible la catégorie \"Autres\". N’y mets une image que si elle est vraiment impossible à classer ailleurs.\n",
    "\n",
    "                - Listes de mots-clés détectés pour chaque image dans le format dict = \"image_name\": [mots-cles] : {subset_keywords}\n",
    "\n",
    "                Retourne uniquement le résultat et au format JSON : {{ \"categorie1\": [ \"image_name\", \"image_name\" ], \"categorie2\": [ \"image_name\", \"image_name\" ],...}}\"\"\"\n",
    "            }\n",
    "\n",
    "            categories_output = call_func(cat_chain, prompt)\n",
    "            print(f\"Categories : {categories_output}\\n\")\n",
    "\n",
    "            if categories_output is None:\n",
    "                max_iter -= 1\n",
    "                print(f\"On re-essaie avec au maximum : {max_iter}\\n\")\n",
    "            else:\n",
    "                df = add_categories_to_df(df, categories_output)\n",
    "                cat_list = get_cat_list(df, cat_list)\n",
    "                print(f\"Nouvelle liste des categories : {cat_list}\")\n",
    "                wrong_json = False\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb4c5dbb0ffa3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:09:02.495813Z",
     "start_time": "2025-03-21T15:09:02.491479Z"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline_categories(image_data, limit_size=20):\n",
    "    new_keywords = image_data.set_index(\"image_name\")[\"keywords\"].to_dict()\n",
    "    #print(new_keywords)\n",
    "    cat_list = [\"Paysage\", \"Ville\", \"Plage\", \"Randonnée\", \"Sport\", \"Musée\", \"Restaurant\", \"Autres\"]\n",
    "\n",
    "    prompt_chain = RunnableLambda(prompt_func)\n",
    "    cat_chain = prompt_chain | llm\n",
    "\n",
    "    all_categories = False\n",
    "    only_once = False\n",
    "\n",
    "    while not all_categories:\n",
    "        image_data = categories_call(image_data, new_keywords, limit_size, cat_list, cat_chain)\n",
    "\n",
    "        if only_once:\n",
    "            image_data.loc[1, \"categories\"] = None\n",
    "            only_once = False\n",
    "\n",
    "\n",
    "        new_keywords = checking_all_categories(image_data)\n",
    "        print(f\"Kewords à repasser après checking : {new_keywords}\")\n",
    "        cat_list = get_cat_list(image_data, cat_list)\n",
    "\n",
    "        if not new_keywords:\n",
    "            all_categories = True\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b77397eb7820b22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:11:02.298620Z",
     "start_time": "2025-03-21T15:09:02.502736Z"
    }
   },
   "outputs": [],
   "source": [
    "copy_image_data = pipeline_categories(image_data, limit_size=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c575ea743e9b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:11:02.329453Z",
     "start_time": "2025-03-21T15:11:02.314398Z"
    }
   },
   "outputs": [],
   "source": [
    "print(tabulate(copy_image_data, headers=\"keys\", tablefmt=\"psql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb3a4d3dd939f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:18:49.154796Z",
     "start_time": "2025-03-21T15:18:49.150578Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_name = directory + \".csv\"\n",
    "copy_image_data.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8885a4",
   "metadata": {},
   "source": [
    "## Tests Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ccb05a2f11c8081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catégories avec Embeddings\n",
    "def categories_from_embeddings(df, embeddings_model=\"mxbai-embed-large\", predefined_categories=None):\n",
    "    embeddings = OllamaEmbeddings(model=embeddings_model)\n",
    "\n",
    "    # Catégories prédéfinies par défaut\n",
    "    if predefined_categories is None:\n",
    "        predefined_categories = [\"Paysage\", \"Ville\", \"Plage\", \"Randonnée\", \"Sport\", \"Musée\", \"Restaurant\", \"Autres\"]\n",
    "\n",
    "    df_keywords = df.dropna(subset=['keywords']).copy()\n",
    "\n",
    "    # Convertir les mots-clés en texte\n",
    "    def keywords_to_text(keywords):\n",
    "        try:\n",
    "            keywords_list = ast.literal_eval(keywords)\n",
    "            return ' '.join(str(k).lower() for k in keywords_list if k)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la conversion des keywords: {e}\")\n",
    "            return \"\"\n",
    "        \n",
    "    df_keywords['keyword_text'] = df_keywords['keywords'].apply(keywords_to_text)\n",
    "\n",
    "    def assign_category(keywords):\n",
    "        if not keywords or keywords.strip() == \"\":\n",
    "            return \"Autres\"\n",
    "\n",
    "        # Générer l'embedding\n",
    "        try:\n",
    "            keyword_embedding = embeddings.embed_documents([keywords])[0]\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur d'embedding: {e}\")\n",
    "            return \"Autres\"\n",
    "            \n",
    "        category_embeddings = embeddings.embed_documents(predefined_categories)\n",
    "            \n",
    "        # Calculer les similarités cosinus\n",
    "        similarities = cosine_similarity([keyword_embedding], category_embeddings)[0]\n",
    "\n",
    "        # Normalisation des similarités\n",
    "        normalized_similarities = (similarities - np.min(similarities)) / (np.max(similarities) - np.min(similarities) + 1e-8)\n",
    "    \n",
    "        print(f\"Keywords: {keywords}\")\n",
    "        for cat, sim in zip(predefined_categories, normalized_similarities):\n",
    "            print(f\"{cat}: {sim:.3f}\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Mappings spécifiques pour affiner la classification\n",
    "        general_mappings = {\n",
    "            \"Randonnée\": [\n",
    "                \"forêt\", \"chemin\", \"sentier\", \"arbres\", \"montagne\",\n",
    "                \"promenade\", \"parcours\"],\n",
    "            \"Plage\": [\n",
    "                \"sable\", \"mer\", \"océan\", \"côte\", \"littoral\",\n",
    "                \"soleil\", \"baignade\", \"bord de mer\"],\n",
    "            \"Ville\": [\n",
    "                \"bâtiments\", \"architecture\", \"urbain\", \"métropole\",\n",
    "                \"rue\", \"infrastructure\", \"quartier\", \"centre-ville\"],\n",
    "            \"Restaurant\": [\n",
    "                \"repas\", \"gastronomie\", \"cuisine\", \"plat\", \"menu\",\n",
    "                \"dîner\", \"brunch\", \"alimentaire\"],\n",
    "            \"Musée\": [\n",
    "                \"art\", \"culture\", \"histoire\", \"exposition\", \"patrimoine\",\n",
    "                \"galerie\", \"collection\"],\n",
    "            \"Paysage\": [\n",
    "                \"panorama\", \"vue\", \"décor\", \"nature\", \"étendue\",\n",
    "                \"campagne\"],\n",
    "            \"Sport\": [\n",
    "                \"athlétisme\", \"compétition\", \"entraînement\", \"stade\",\n",
    "                \"exercice\", \"match\", \"activité physique\", \"performance\"]\n",
    "        }\n",
    "\n",
    "        # Vérification des mappings spécifiques\n",
    "        keywords_lower = keywords.lower()\n",
    "        for category, mapping_keywords in general_mappings.items():\n",
    "            if any(mapping_kw in keywords_lower for mapping_kw in mapping_keywords):\n",
    "                return category\n",
    "\n",
    "        # Décision finale basée sur la similarité\n",
    "        max_similarity = np.max(normalized_similarities)\n",
    "        best_category_index = np.argmax(normalized_similarities)\n",
    "        \n",
    "        # Vérifier l'écart avec la catégorie \"Autres\"\n",
    "        if \"Autres\" in predefined_categories:\n",
    "            others_index = predefined_categories.index(\"Autres\")\n",
    "            others_similarity = normalized_similarities[others_index]\n",
    "        else:\n",
    "            others_similarity = 0\n",
    "\n",
    "        difference = max_similarity - others_similarity\n",
    "        \n",
    "        # Si la différence est trop faible retourner \"Autres\"\n",
    "        if difference < 0.2:\n",
    "            return \"Autres\"\n",
    "        else:\n",
    "            return predefined_categories[best_category_index]\n",
    "    \n",
    "    df_keywords['categories'] = df_keywords['keyword_text'].apply(assign_category)\n",
    "    \n",
    "    categories_output = {}\n",
    "    for category in set(df_keywords['categories']):\n",
    "        categories_output[category] = df_keywords[df_keywords['categories'] == category]['image_name'].tolist()\n",
    "\n",
    "    return df_keywords[['image_name', 'keywords', 'categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36f05932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords: chemin forêt arbres sentier ombre\n",
      "Paysage: 0.924\n",
      "Ville: 0.841\n",
      "Plage: 0.637\n",
      "Randonnée: 1.000\n",
      "Sport: 0.000\n",
      "Musée: 0.512\n",
      "Restaurant: 0.250\n",
      "Autres: 0.952\n",
      "\n",
      "\n",
      "Keywords: conteneurs lasagnes plat cuisine cuisson\n",
      "Paysage: 0.588\n",
      "Ville: 0.592\n",
      "Plage: 0.930\n",
      "Randonnée: 0.195\n",
      "Sport: 0.000\n",
      "Musée: 0.255\n",
      "Restaurant: 1.000\n",
      "Autres: 0.690\n",
      "\n",
      "\n",
      "Keywords: bâtiments gazon pavillon ciel espace\n",
      "Paysage: 0.185\n",
      "Ville: 0.979\n",
      "Plage: 0.819\n",
      "Randonnée: 0.255\n",
      "Sport: 0.000\n",
      "Musée: 1.000\n",
      "Restaurant: 0.261\n",
      "Autres: 0.979\n",
      "\n",
      "\n",
      "Keywords: architecture voiture rue reflets pluie\n",
      "Paysage: 0.608\n",
      "Ville: 0.958\n",
      "Plage: 1.000\n",
      "Randonnée: 0.638\n",
      "Sport: 0.000\n",
      "Musée: 0.801\n",
      "Restaurant: 0.563\n",
      "Autres: 0.529\n",
      "\n",
      "\n",
      "Keywords: chaussures clogs étagères couleurs magasin\n",
      "Paysage: 0.627\n",
      "Ville: 0.541\n",
      "Plage: 0.544\n",
      "Randonnée: 0.386\n",
      "Sport: 0.000\n",
      "Musée: 0.848\n",
      "Restaurant: 0.233\n",
      "Autres: 1.000\n",
      "\n",
      "\n",
      "Keywords: pot beurre supermarché texture beurre\n",
      "Paysage: 1.000\n",
      "Ville: 0.674\n",
      "Plage: 0.764\n",
      "Randonnée: 0.279\n",
      "Sport: 0.000\n",
      "Musée: 0.416\n",
      "Restaurant: 0.545\n",
      "Autres: 0.891\n",
      "\n",
      "\n",
      "Keywords: bâtiment panneau ville herbe éclairage\n",
      "Paysage: 0.360\n",
      "Ville: 1.000\n",
      "Plage: 0.406\n",
      "Randonnée: 0.345\n",
      "Sport: 0.056\n",
      "Musée: 0.515\n",
      "Restaurant: 0.000\n",
      "Autres: 0.530\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>keywords</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>['Chemin', 'Forêt', 'Arbres', 'Sentier', 'Ombre']</td>\n",
       "      <td>Randonnée</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img2.jpg</td>\n",
       "      <td>['conteneurs', 'lasagnes', 'plat', 'cuisine', ...</td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img3.jpg</td>\n",
       "      <td>['Bâtiments', 'Gazon', 'Pavillon', 'Ciel', 'Es...</td>\n",
       "      <td>Ville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img4.jpg</td>\n",
       "      <td>['Architecture', 'Voiture', 'Rue', 'Reflets', ...</td>\n",
       "      <td>Ville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img5.jpg</td>\n",
       "      <td>['Chaussures', 'Clogs', 'Étagères', 'Couleurs'...</td>\n",
       "      <td>Autres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img6.jpg</td>\n",
       "      <td>['Pot', 'Beurre', 'Supermarché', 'Texture', 'B...</td>\n",
       "      <td>Autres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>img7.jpg</td>\n",
       "      <td>['Bâtiment', 'Panneau', 'Ville', 'Herbe', 'Écl...</td>\n",
       "      <td>Ville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                           keywords  categories\n",
       "0   img1.jpg  ['Chemin', 'Forêt', 'Arbres', 'Sentier', 'Ombre']   Randonnée\n",
       "1   img2.jpg  ['conteneurs', 'lasagnes', 'plat', 'cuisine', ...  Restaurant\n",
       "2   img3.jpg  ['Bâtiments', 'Gazon', 'Pavillon', 'Ciel', 'Es...       Ville\n",
       "3   img4.jpg  ['Architecture', 'Voiture', 'Rue', 'Reflets', ...       Ville\n",
       "4   img5.jpg  ['Chaussures', 'Clogs', 'Étagères', 'Couleurs'...      Autres\n",
       "5   img6.jpg  ['Pot', 'Beurre', 'Supermarché', 'Texture', 'B...      Autres\n",
       "6   img7.jpg  ['Bâtiment', 'Panneau', 'Ville', 'Herbe', 'Écl...       Ville"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'image_name': ['img1.jpg', 'img2.jpg', 'img3.jpg', 'img4.jpg', 'img5.jpg', 'img6.jpg', 'img7.jpg'],\n",
    "    'keywords': [\n",
    "        \"['Chemin', 'Forêt', 'Arbres', 'Sentier', 'Ombre']\",\n",
    "        \"['conteneurs', 'lasagnes', 'plat', 'cuisine', 'cuisson']\",\n",
    "        \"['Bâtiments', 'Gazon', 'Pavillon', 'Ciel', 'Espace']\",\n",
    "        \"['Architecture', 'Voiture', 'Rue', 'Reflets', 'Pluie']\",\n",
    "        \"['Chaussures', 'Clogs', 'Étagères', 'Couleurs', 'Magasin']\",\n",
    "        \"['Pot', 'Beurre', 'Supermarché', 'Texture', 'Beurre']\",\n",
    "        \"['Bâtiment', 'Panneau', 'Ville', 'Herbe', 'Éclairage']\"\n",
    "        ]\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "result_df = categories_from_embeddings(df)  \n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
