{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-23T14:28:43.571799Z",
     "start_time": "2025-04-23T14:28:43.568822Z"
    }
   },
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T14:28:43.592603Z",
     "start_time": "2025-04-23T14:28:43.589720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_image_paths(directory):\n",
    "    allowed_extensions = {\".jpg\", \".jpeg\", \".png\"}\n",
    "    image_paths = [os.path.join(directory, filename) for filename in os.listdir(directory) if os.path.splitext(filename)[1].lower() in allowed_extensions]\n",
    "    return image_paths"
   ],
   "id": "8718bc882b71e5d7",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T14:28:43.601759Z",
     "start_time": "2025-04-23T14:28:43.598608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_df(image_paths):\n",
    "    image_list = []\n",
    "    for path in image_paths:\n",
    "        image = Image.open(path)\n",
    "        image_name = os.path.basename(path)\n",
    "        exifdata = image._getexif()\n",
    "        date_time, localisation = None, None\n",
    "        if exifdata:\n",
    "            for tag_id, value in exifdata.items():\n",
    "                tag = Image.ExifTags.TAGS.get(tag_id, tag_id)\n",
    "                if tag == \"DateTime\":\n",
    "                    date_time = value\n",
    "                elif tag == \"GPSInfo\":\n",
    "                    localisation = value\n",
    "\n",
    "            image_list.append((image_name, path, date_time, localisation))\n",
    "\n",
    "        else:\n",
    "            print(\"Aucune donnée EXIF trouvée.\")\n",
    "\n",
    "    df = pd.DataFrame(image_list, columns=[\"image_name\", \"path\", \"date_time\", \"localisation\"])\n",
    "    df[\"keywords\"] = \"\"\n",
    "    df[\"categories\"] = \"\"\n",
    "\n",
    "    return df"
   ],
   "id": "f3a5172f2eb96238",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T14:28:43.610503Z",
     "start_time": "2025-04-23T14:28:43.607067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "directory = \"temp\"\n",
    "image_paths = get_image_paths(directory)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "id": "435ba366c1207438",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T14:28:43.618464Z",
     "start_time": "2025-04-23T14:28:43.615553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def image_embedding(paths):\n",
    "    clip_model = CLIPModel.from_pretrained(\"laion/CLIP-ViT-L-14-laion2B-s32B-b82K\").to(device)\n",
    "    clip_processor = CLIPProcessor.from_pretrained(\"laion/CLIP-ViT-L-14-laion2B-s32B-b82K\")\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for path in paths:\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        images.append(image)\n",
    "\n",
    "    # Prétraitement des images en batch\n",
    "    image_inputs = clip_processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_embeddings = clip_model.get_image_features(**image_inputs)\n",
    "\n",
    "    # Normalisation\n",
    "    image_embeddings = image_embeddings / image_embeddings.norm(p=2, dim=-1, keepdim=True)\n",
    "    image_embeddings = image_embeddings.cpu().numpy()\n",
    "\n",
    "    return image_embeddings\n"
   ],
   "id": "182783a057c92db1",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "def similarity_call(embeddings, n_neighbors, paths):\n",
    "    N = embeddings.shape[0]\n",
    "    result = {}\n",
    "    image_names = [os.path.basename(path) for path in paths]\n",
    "\n",
    "    for i in range(N):\n",
    "        image_simi = {}\n",
    "        neighbors_simi = []\n",
    "        for j in range(1, n_neighbors + 1):\n",
    "            if i + j < N:\n",
    "                sim = np.dot(embeddings[i], embeddings[i + j])\n",
    "                image_name = image_names[i + j]\n",
    "                #image_simi.update({image_name: sim})\n",
    "                neighbors_simi.append({image_name: sim.item()})\n",
    "\n",
    "        result.update({image_names[i]: neighbors_simi})\n",
    "\n",
    "    return result\n"
   ],
   "id": "d94ecbffe32dda33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T14:32:15.319100Z",
     "start_time": "2025-04-23T14:32:02.702041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "embedded_images = image_embedding(image_paths)"
   ],
   "id": "42944cecee4ef047",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T14:34:14.038661Z",
     "start_time": "2025-04-23T14:34:14.033656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sequential_clustering(embeddings, paths, threshold=0.6, n_neighbors=3):\n",
    "    image_names = [os.path.basename(path) for path in paths]\n",
    "    N = len(image_names)\n",
    "    clusters = {}\n",
    "    cluster_id = 0\n",
    "    current_cluster = []\n",
    "\n",
    "    for i in range(N):\n",
    "        current_image = image_names[i]\n",
    "        has_strong_link = False\n",
    "\n",
    "        for j in range(1, n_neighbors + 1):\n",
    "            if i + j < N:\n",
    "                sim = np.dot(embeddings[i], embeddings[i + j])\n",
    "                if sim > threshold:\n",
    "                    has_strong_link = True\n",
    "                    break\n",
    "\n",
    "        current_cluster.append(current_image)\n",
    "\n",
    "        if not has_strong_link:\n",
    "            clusters[f\"cluster_{cluster_id}\"] = current_cluster\n",
    "            cluster_id += 1\n",
    "            current_cluster = []\n",
    "\n",
    "    # Gère le dernier cluster s'il reste des images non assignées\n",
    "    if current_cluster:\n",
    "        clusters[f\"cluster_{cluster_id}\"] = current_cluster\n",
    "\n",
    "    return clusters"
   ],
   "id": "6ac692364dfa2897",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T14:34:21.144028Z",
     "start_time": "2025-04-23T14:34:21.140629Z"
    }
   },
   "cell_type": "code",
   "source": "clusters = sequential_clustering(embedded_images, image_paths)",
   "id": "1c8fbbc37e9e7b64",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T14:34:21.680506Z",
     "start_time": "2025-04-23T14:34:21.675065Z"
    }
   },
   "cell_type": "code",
   "source": "print(clusters)",
   "id": "347ff92dd190daa0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cluster_0': ['IMG_20250105_144147.jpg', 'IMG_20250105_144436.jpg', 'IMG_20250105_144540.jpg', 'IMG_20250105_144750.jpg', 'IMG_20250105_145543_BURST1.jpg', 'IMG_20250105_150144.jpg'], 'cluster_1': ['IMG_20250105_161636.jpg', 'IMG_20250105_165438.jpg', 'IMG_20250105_165450.jpg', 'IMG_20250105_165457.jpg'], 'cluster_2': ['IMG_20250107_180316.jpg'], 'cluster_3': ['IMG_20250108_143517.jpg'], 'cluster_4': ['IMG_20250109_174849.jpg'], 'cluster_5': ['IMG_20250110_163528.jpg'], 'cluster_6': ['IMG_20250110_164345.jpg'], 'cluster_7': ['IMG_20250111_152149.jpg', 'IMG_20250111_152150.jpg', 'IMG_20250111_154046.jpg'], 'cluster_8': ['IMG_20250113_201010.jpg'], 'cluster_9': ['IMG_20250114_193654.jpg'], 'cluster_10': ['IMG_20250119_131124_BURST1.jpg', 'IMG_20250119_131214_BURST1.jpg'], 'cluster_11': ['IMG_20250119_131317.jpg'], 'cluster_12': ['IMG_20250119_131334_BURST1.jpg', 'IMG_20250119_131335.jpg', 'IMG_20250119_131815_BURST1.jpg'], 'cluster_13': ['IMG_20250122_093940.jpg'], 'cluster_14': ['IMG_20250122_155558.jpg', 'IMG_20250122_162438.jpg'], 'cluster_15': ['IMG_20250124_092053.jpg', 'IMG_20250124_092101.jpg'], 'cluster_16': ['IMG_20250124_092335.jpg']}\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T14:34:22.391420Z",
     "start_time": "2025-04-23T14:34:22.388557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for cluster_id, images in clusters.items():\n",
    "    for image in images:\n",
    "        print(f\"{cluster_id} : {image}\")\n",
    "    print(\"\\n\")"
   ],
   "id": "a19f721a521e38b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_0 : IMG_20250105_144147.jpg\n",
      "cluster_0 : IMG_20250105_144436.jpg\n",
      "cluster_0 : IMG_20250105_144540.jpg\n",
      "cluster_0 : IMG_20250105_144750.jpg\n",
      "cluster_0 : IMG_20250105_145543_BURST1.jpg\n",
      "cluster_0 : IMG_20250105_150144.jpg\n",
      "\n",
      "\n",
      "cluster_1 : IMG_20250105_161636.jpg\n",
      "cluster_1 : IMG_20250105_165438.jpg\n",
      "cluster_1 : IMG_20250105_165450.jpg\n",
      "cluster_1 : IMG_20250105_165457.jpg\n",
      "\n",
      "\n",
      "cluster_2 : IMG_20250107_180316.jpg\n",
      "\n",
      "\n",
      "cluster_3 : IMG_20250108_143517.jpg\n",
      "\n",
      "\n",
      "cluster_4 : IMG_20250109_174849.jpg\n",
      "\n",
      "\n",
      "cluster_5 : IMG_20250110_163528.jpg\n",
      "\n",
      "\n",
      "cluster_6 : IMG_20250110_164345.jpg\n",
      "\n",
      "\n",
      "cluster_7 : IMG_20250111_152149.jpg\n",
      "cluster_7 : IMG_20250111_152150.jpg\n",
      "cluster_7 : IMG_20250111_154046.jpg\n",
      "\n",
      "\n",
      "cluster_8 : IMG_20250113_201010.jpg\n",
      "\n",
      "\n",
      "cluster_9 : IMG_20250114_193654.jpg\n",
      "\n",
      "\n",
      "cluster_10 : IMG_20250119_131124_BURST1.jpg\n",
      "cluster_10 : IMG_20250119_131214_BURST1.jpg\n",
      "\n",
      "\n",
      "cluster_11 : IMG_20250119_131317.jpg\n",
      "\n",
      "\n",
      "cluster_12 : IMG_20250119_131334_BURST1.jpg\n",
      "cluster_12 : IMG_20250119_131335.jpg\n",
      "cluster_12 : IMG_20250119_131815_BURST1.jpg\n",
      "\n",
      "\n",
      "cluster_13 : IMG_20250122_093940.jpg\n",
      "\n",
      "\n",
      "cluster_14 : IMG_20250122_155558.jpg\n",
      "cluster_14 : IMG_20250122_162438.jpg\n",
      "\n",
      "\n",
      "cluster_15 : IMG_20250124_092053.jpg\n",
      "cluster_15 : IMG_20250124_092101.jpg\n",
      "\n",
      "\n",
      "cluster_16 : IMG_20250124_092335.jpg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T14:28:56.805167300Z",
     "start_time": "2025-04-23T13:21:40.638785Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "37d61a75410d0042",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
